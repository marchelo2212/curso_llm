{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/marchelo2212/curso_llm/blob/main/notebooks/est_notebook_0_introduccion_langchain_rag.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Escuela Colombiana de Ingeniería Julio Garavito\n",
        "\n",
        "## Taller de Inteligencia Artificial Aplicada a la Educaicón - Avanzado\n",
        "\n",
        "**Facilitador:** Marcelo Sotaminga\n",
        "\n",
        "**OCT-2025**\n"
      ],
      "metadata": {
        "id": "ppWKk7QNW5nu"
      },
      "id": "ppWKk7QNW5nu"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Estimado participante, dentro de este cuaderno se presnetarán una serie de ejercicios articulas a que usted conozca el framework LangChain, su potencialidad y manera de uso desde un enfoque técnico.\n",
        "\n",
        "El Objetivo que se persigue con este taller es:\n",
        "\n",
        "Lograr conocimientos sólidos sobre langchain para la elaboración de un proyecto/prototipo de artefacto tecnológico que emplee un LLM y que atienda una necesidad particulr del participante.\n",
        "\n",
        "Para alcanzar este objetivo se desarrollarán 4 cuadernos de google colab con esstos detalles:\n",
        "\n",
        "1. Cuaderno 0 — Introducción a LangChain y fundamentos prácticos de RAG\n",
        "2. Notebook 1: Chatbot con FAQ /QA\n",
        "3. Notebook 2: Chatbot RAG\n",
        "4. Notebook 3: Chatbot RAG con memoria\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "CulJZwP5W8h-"
      },
      "id": "CulJZwP5W8h-"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9LogvD83W1G5"
      },
      "source": [
        "# Cuaderno 0 — Introducción a LangChain y fundamentos prácticos de RAG\n",
        "\n",
        "**Duración sugerida:** 45–60 min  \n",
        "**Objetivo:** activar conocimientos previos sobre LLMs y conectar los componentes básicos de LangChain que luego se usarán en las prácticas de **FAQ Bot** y **Chatbot RAG**.\n",
        "\n",
        "> **Requisitos:** Cuenta en Google Colab con acceso a Internet y una clave de API de OpenAI (o usa un modelo local/alternativo si lo prefieres)."
      ],
      "id": "9LogvD83W1G5"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "78j-s_KDW1G7"
      },
      "source": [
        "## Agenda del cuaderno\n",
        "1. Preparación del entorno (instalación y claves)\n",
        "2. Primer ejemplo: llamada simple a un modelo vía LangChain\n",
        "3. PromptTemplate + LLMChain (encadenando un prompt)\n",
        "4. Carga de documentos (PDF) con `DocumentLoader`\n",
        "5. División del texto (chunking) con `TextSplitter`\n",
        "6. Introducción rápida a embeddings\n",
        "7. Mini‑ejercicio de comprensión\n",
        "8. Conclusión y siguiente paso"
      ],
      "id": "78j-s_KDW1G7"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2fNJV5EtW1G7"
      },
      "source": [
        "## 1) Preparación del entorno\n",
        "Ejecuta la celda siguiente para instalar dependencias mínimas. En Colab tardará ~1–3 minutos.\n",
        "\n",
        "**Paquetes a instalar**\n",
        "- `langchain` y `langchain-openai`: orquestación y wrapper de OpenAI para LangChain.\n",
        "- `chromadb`: vector store local liviano (se usará en el siguiente cuaderno de RAG).\n",
        "- `tiktoken`: tokenizador útil para contar tokens.\n",
        "- `pypdf`: extracción de texto desde PDF.\n"
      ],
      "id": "2fNJV5EtW1G7"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "instalacion"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "# ⬇️ Instalar dependencias mínimas\n",
        "!pip install -qU \\\n",
        "    langchain \\\n",
        "    langchain-openai \\\n",
        "    chromadb \\\n",
        "    tiktoken \\\n",
        "    pypdf \\\n",
        "    scikit-learn \\\n",
        "    matplotlib \\\n",
        "    numpy"
      ],
      "id": "instalacion"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fz1TzqTxW1G8"
      },
      "source": [
        "### Clave de API (OpenAI)\n",
        "En Colab puedes guardar tu clave de forma temporal:\n",
        "- Ve a `Entorno de ejecución` → `Restablecer estado de fábrica` si es necesario.\n",
        "- Usa la celda siguiente y **sustituye** `TU_API_KEY` por tu clave real.\n",
        "\n",
        "> ⚠️ No compartas tu API key."
      ],
      "id": "Fz1TzqTxW1G8"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "apikey"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['OPENAI_API_KEY'] = 'APIKEY'  # ← Reemplaza por tu clave (o usa otro proveedor en los cuadernos siguientes)\n",
        "print('API key configurada (longitud):', len(os.environ.get('OPENAI_API_KEY','')))"
      ],
      "id": "apikey"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hPAg9aXyW1G8"
      },
      "source": [
        "## 2) Primer ejemplo: pregunta directa al modelo\n",
        "Mostramos cómo LangChain abstrae el uso de un LLM.\n",
        "\n",
        "> **Reflexión:** Este enfoque **no** tiene memoria, ni grounding, ni control fino del contexto."
      ],
      "id": "hPAg9aXyW1G8"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "primer-ejemplo"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "# Temperatura baja para mayor determinismo en ejemplos docentes\n",
        "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
        "resp = llm.invoke(\"Explica en 3 líneas qué es la inteligencia artificial generativa.\")\n",
        "print(resp.content)"
      ],
      "id": "primer-ejemplo"
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### 2.1) Ejercicio práctico\n",
        "Agregue aquí el código para ejecutar una pregunta diferente a la ubicada en el cuaderno.\n",
        "Aquí `modifica la pregunta`, intenta lograr que el `modelo falle o responda equivocadamente`.\n"
      ],
      "metadata": {
        "id": "oXVc3iqnt7zL"
      },
      "id": "oXVc3iqnt7zL"
    },
    {
      "cell_type": "code",
      "source": [
        "#Aquí tu código\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "tsdDZr5nt7ba"
      },
      "id": "tsdDZr5nt7ba",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### 2.2) Ejercicio práctico\n",
        "Agregue aquí el código para ejecutar una pregunta diferente a la ubicada en el cuaderno.\n",
        "Aquí modifica el `modelo de OpenAI`, investiga cuáles son los modelos que existen. Cambia por alguno que halles, responde ¿Ha funcionado la consulta? ¿Su respuesta ha cambiado? ¿En caso que no haya funcionado, por qué pasa esto?\n"
      ],
      "metadata": {
        "id": "ZAYFsEE8utpp"
      },
      "id": "ZAYFsEE8utpp"
    },
    {
      "cell_type": "code",
      "source": [
        "#Aquí tu código"
      ],
      "metadata": {
        "id": "pR0QXAWUus9i"
      },
      "id": "pR0QXAWUus9i",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Agrega aquí tus respuestas a la pregunta.\n",
        "\n",
        "\n",
        "> Respuestas...\n",
        "\n"
      ],
      "metadata": {
        "id": "vbfFDzhTwz7H"
      },
      "id": "vbfFDzhTwz7H"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JlodxeJGW1G8"
      },
      "source": [
        "## 3) PromptTemplate + LLMChain\n",
        "Un *PromptTemplate* permite definir una plantilla con **variables**. Con `LLMChain` unimos el modelo y el prompt, creando un bloque reutilizable."
      ],
      "id": "JlodxeJGW1G8"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "prompt-chain"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
        "template = (\n",
        "    \"\"\"\n",
        "Eres un profesor de ingeniería. Resume el siguiente concepto en lenguaje técnico y claro.\n",
        "Incluye un ejemplo breve. Limita la respuesta a 4 líneas.\n",
        "Concepto: {concepto}\n",
        "\"\"\"\n",
        ")\n",
        "prompt = PromptTemplate(template=template, input_variables=[\"concepto\"])\n",
        "chain = prompt | llm\n",
        "\n",
        "print(chain.invoke({\"concepto\": \"aprendizaje supervisado\"}))"
      ],
      "id": "prompt-chain"
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## 3.1) Ejercicio práctico\n",
        "Modifica aquí el código y adecua a tu área de conocimiento.\n"
      ],
      "metadata": {
        "id": "gdIAMpdytFgs"
      },
      "id": "gdIAMpdytFgs"
    },
    {
      "cell_type": "code",
      "source": [
        "#Aquí tu código\n"
      ],
      "metadata": {
        "id": "vf8FgVawtgiB"
      },
      "id": "vf8FgVawtgiB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## 3.2) Ejercicio práctico\n",
        "Agrega la posibilidad que se modifique el modelo de IA usando en la consulta.\n"
      ],
      "metadata": {
        "id": "odWF0DqhvyNv"
      },
      "id": "odWF0DqhvyNv"
    },
    {
      "cell_type": "code",
      "source": [
        "#Aquí tu código"
      ],
      "metadata": {
        "id": "Ted1dCoFvunD"
      },
      "id": "Ted1dCoFvunD",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## 3.3) Ejercicio práctico\n",
        "Modifica el template del prompt de tal manera que el usuario ingrese:\n",
        "1. Área del conocimiento.\n",
        "2. Concepto"
      ],
      "metadata": {
        "id": "U9rrsdPb1paz"
      },
      "id": "U9rrsdPb1paz"
    },
    {
      "cell_type": "code",
      "source": [
        "#Aquí tu código"
      ],
      "metadata": {
        "id": "SLM8gj_V1tT3"
      },
      "id": "SLM8gj_V1tT3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m3nnNfWsW1G8"
      },
      "source": [
        "## 4) Carga de documentos (PDF) con `DocumentLoader`\n",
        "Para esta demostración subiremos un **PDF corto**. En Colab:\n",
        "1) Ejecuta la celda, 2) Elige un PDF desde tu PC, 3) Confirma el nombre del archivo cargado."
      ],
      "id": "m3nnNfWsW1G8"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "upload-pdf"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()  # ← Selecciona un PDF corto (1–3 páginas)\n",
        "uploaded_files = list(uploaded.keys())\n",
        "uploaded_files[:3]"
      ],
      "id": "upload-pdf"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "load-pdf"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "#!pip install -U langchain_community\n",
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "\n",
        "pdf_path = uploaded_files[0]\n",
        "loader = PyPDFLoader(pdf_path)\n",
        "docs = loader.load()\n",
        "print(f\"Páginas extraídas: {len(docs)}\")\n",
        "print(\"\\nVista previa de la primera página (primeros 500 chars):\\n\")\n",
        "print(docs[0].page_content[:500])"
      ],
      "id": "load-pdf"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "706ljyIgW1G9"
      },
      "source": [
        "## 5) División del texto (chunking)\n",
        "Dividimos el documento en fragmentos manejables. Esto prepara el material para **retrieval** y evita desbordar la ventana de contexto del LLM."
      ],
      "id": "706ljyIgW1G9"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "chunking"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "\n",
        "splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=500,      # tamaño del fragmento (ajustable)\n",
        "    chunk_overlap=100,   # solape entre fragmentos para mantener continuidad\n",
        ")\n",
        "chunks = splitter.split_documents(docs)\n",
        "print(f\"Total de fragmentos: {len(chunks)}\")\n",
        "print(\"\\nPrimer fragmento:\\n\", chunks[0].page_content[:400])"
      ],
      "id": "chunking"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.1 Investiga y responde\n",
        "**¿Por qué es importante hacer `chunl_overlap`?**\n",
        "\n",
        "\n",
        "> Respuesta\n",
        "\n",
        "**¿Cuál es el tamaño ideal del chunk_size? ¿Por qué?**\n",
        "\n",
        "\n",
        "> Respuesta\n"
      ],
      "metadata": {
        "id": "hT-X7bQv7kq_"
      },
      "id": "hT-X7bQv7kq_"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kzGZXY06W1G9"
      },
      "source": [
        "## 6) Introducción rápida a embeddings\n",
        "Un *embedding* es una representación numérica (vector) del significado de un texto. Nos permite medir **similitud semántica** entre fragmentos y consultas.\n",
        "\n",
        "Ejecuta la siguiente celda para generar un embedding de ejemplo y observar su dimensión."
      ],
      "id": "kzGZXY06W1G9"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "embeddings"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "from langchain_openai import OpenAIEmbeddings\n",
        "\n",
        "# Try a different model that might be available\n",
        "embedder = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
        "vec = embedder.embed_query(\"mecánica de fluidos\")\n",
        "print(\"Dimensión del embedding:\", len(vec))\n",
        "print(\"Primeros 8 valores:\", [round(v, 4) for v in vec[:8]])"
      ],
      "id": "embeddings"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aquí compararemos la similitud semántica del embedding \"mecánica de fluidos\" con otros dos \"Ingeniería hidráulica\" y \"Receta de pasteles\""
      ],
      "metadata": {
        "id": "AmE9J2aFF5M_"
      },
      "id": "AmE9J2aFF5M_"
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Instalación\n",
        "!pip install -qU scikit-learn\n",
        "\n",
        "# 2. Importaciones\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# 3. Configurar el embedder\n",
        "embedder = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
        "\n",
        "# 4. Crear los vectores\n",
        "print(\"Generando embeddings...\")\n",
        "vec_1 = embedder.embed_query(\"mecánica de fluidos\")\n",
        "vec_similar = embedder.embed_query(\"ingeniería hidráulica\")\n",
        "vec_diferente = embedder.embed_query(\"receta de pastel\")\n",
        "print(\"Dimensión (vec_1):\", len(vec_1))\n",
        "\n",
        "\n",
        "# 5. Calcular la similitud\n",
        "# Nota: cosine_similarity espera listas de vectores (2D), por eso usamos [vec_1]\n",
        "sim_1_vs_similar = cosine_similarity([vec_1], [vec_similar])[0][0]\n",
        "sim_1_vs_diferente = cosine_similarity([vec_1], [vec_diferente])[0][0]\n",
        "\n",
        "# 6. Mostrar resultados\n",
        "print(\"\\n--- Resultados de Similitud (1.0 es idéntico) ---\")\n",
        "print(f\"Fluidos vs. Hidráulica: {sim_1_vs_similar:.4f}\")\n",
        "print(f\"Fluidos vs. Pastel:     {sim_1_vs_diferente:.4f}\")"
      ],
      "metadata": {
        "id": "ORGlXl1NF4HA"
      },
      "id": "ORGlXl1NF4HA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Explicitly install a compatible version of scikit-learn and dependencies\n",
        "\n",
        "\n",
        "# 2. Importaciones\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "from sklearn.decomposition import PCA\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# 3. Lista de textos a comparar\n",
        "textos = [\n",
        "    \"mecánica de fluidos\",   # Ingeniería\n",
        "    \"ingeniería hidráulica\", # Ingeniería (similar)\n",
        "    \"aerodinámica\",          # Ingeniería (relacionado)\n",
        "    \"flujo laminar\",         # Ingeniería (concepto específico)\n",
        "    \"receta de pastel\",      # Cocina\n",
        "    \"literatura clásica\",    # Humanidades\n",
        "    \"filosofía\"              # Humanidades (similar)\n",
        "]\n",
        "\n",
        "# 4. Configurar y generar embeddings (de las palabras)\n",
        "print(\"Generando embeddings (1536-D)...\")\n",
        "# Suponiendo que el embedder esté definido en otro lugar.\n",
        "embedder = OpenAIEmbeddings(model=\"text-embedding-3-small\") # Assuming you have access to this model\n",
        "vectores = embedder.embed_documents(textos)\n",
        "\n",
        "# 5. Reducción de Dimensionalidad (Necesaria para poder graficar)\n",
        "print(\"Reduciendo dimensiones de 1536-D a 2-D con PCA...\")\n",
        "\n",
        "# Convertir la lista de vectores a un formato que PCA entienda (NumPy array)\n",
        "X = np.array(vectores)\n",
        "\n",
        "# Configurar PCA para reducir a 2 componentes (dimensiones)\n",
        "pca = PCA(n_components=2)\n",
        "\n",
        "# Ejecutar la reducción\n",
        "vectores_2d = pca.fit_transform(X)\n",
        "\n",
        "# 6. Graficar los resultados\n",
        "print(\"Graficando los vectores en 2D...\")\n",
        "plt.figure(figsize=(10, 7))\n",
        "x = vectores_2d[:, 0]  # Coordenada X\n",
        "y = vectores_2d[:, 1]  # Coordenada Y\n",
        "\n",
        "# Dibuja los puntos\n",
        "plt.scatter(x, y, alpha=0.7)\n",
        "\n",
        "# Añade etiquetas a cada punto\n",
        "for i, txt in enumerate(textos):\n",
        "    plt.annotate(txt, (x[i], y[i]), xytext=(5, 2), textcoords='offset points')\n",
        "\n",
        "plt.title(\"Visualización de Embeddings (Reducidos a 2D con PCA)\")\n",
        "plt.xlabel(\"Componente Principal 1\")\n",
        "plt.ylabel(\"Componente Principal 2\")\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "yYZXIpWRI3FK"
      },
      "id": "yYZXIpWRI3FK",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XB8iqfKFW1G9"
      },
      "source": [
        "## 7) Mini‑ejercicio de comprensión\n",
        "Responde en una celda Markdown o en comentarios de código:\n",
        "1. ¿Qué pasos del pipeline RAG ya realizamos aquí?  \n",
        "2. ¿Por qué el *chunking* ayuda a mejorar la recuperación y la calidad de respuesta?  \n",
        "3. ¿Qué limitaciones tiene usar solo el flujo directo `Prompt → LLM` sin retrieval?\n"
      ],
      "id": "XB8iqfKFW1G9"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aquí tus respuestas\n",
        "\n",
        "\n",
        "> Añadir blockquote\n",
        "\n"
      ],
      "metadata": {
        "id": "5R1VjUIfRvnI"
      },
      "id": "5R1VjUIfRvnI"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T1Uw7wxEW1G9"
      },
      "source": [
        "## 8) Conclusión y siguiente paso\n",
        "- Ya conoces los *building blocks* esenciales de LangChain: `DocumentLoader`, `TextSplitter`, `Embeddings` y un primer `LLMChain`.\n",
        "- En el próximo cuaderno implementaremos un **FAQ Bot** (sin retrieval) y luego un **Chatbot RAG** con recuperación semántica y citación de fuentes.\n",
        "\n",
        "### Referencias\n",
        "- P. Lewis *et al.*, “Retrieval‑Augmented Generation for Knowledge‑Intensive NLP Tasks,” NeurIPS 2020. https://arxiv.org/abs/2005.11401\n",
        "- LangChain Docs — Tutorial RAG: https://python.langchain.com/docs/tutorials/rag/\n",
        "- LangChain Docs — Knowledge base: https://docs.langchain.com/oss/python/langchain/knowledge-base\n"
      ],
      "id": "T1Uw7wxEW1G9"
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}